# Feature â†’ API Dependency Map

All 22 system features and which API key each one requires.

```mermaid
flowchart TD
    subgraph KEYS["API Keys"]
        OAI["OPENAI_API_KEY\nâ”â”â”â”â”â”â”\nRequired"]
        ANT["ANTHROPIC_API_KEY\nâ”â”â”â”â”â”â”\nOptional Â· best LLM"]
        GOO["GOOGLE_API_KEY\nâ”â”â”â”â”â”â”\nOptional Â· free tier"]
        ORT["OPENROUTER_API_KEY\nâ”â”â”â”â”â”â”\nOptional Â· free"]
        COH["COHERE_API_KEY\nâ”â”â”â”â”â”â”\nOptional Â· reranking"]
        OLL["Ollama local\nâ”â”â”â”â”â”â”\nNo API Â· offline"]
    end

    LLM(["â›“ Active LLM\nauto-selected Â· first responder wins"])

    ANT  -->|"â‘  claude-sonnet Â· best"| LLM
    OAI  -->|"â‘¡ gpt-4o Â· high quality"| LLM
    GOO  -->|"â‘¢ Gemini 2.5 Pro Â· paid"| LLM
    ORT  -->|"â‘£ DeepSeek V3 Â· free"| LLM
    GOO  -->|"â‘¤ Gemini 2.5 Flash Â· free"| LLM
    OLL  -->|"â‘¥ llama3.2 Â· offline"| LLM

    OAI --> VEC["ğŸ“ Vector indexing\ntext-embedding-3-small"]
    OAI --> SEM["ğŸ’¾ Semantic cache\n92% threshold Â· 7-day TTL"]
    OAI --> VER_E["âœ… Answer verification\nembedding similarity check"]
    OAI --> KGE["ğŸ•¸ KG extraction\ngpt-4o-mini Â· default config"]

    LLM --> ANS["ğŸ’¬ Answer generation"]
    LLM --> DEC["ğŸ”€ Query decomposition\ncomplex â†’ sub-queries"]
    LLM --> REW["âœï¸ LLM query rewrite"]
    LLM --> SRAG["ğŸ”„ Self-RAG retry\nconfidence < 70%"]
    LLM --> COD["ğŸ”¨ Plugin code generation"]
    LLM --> FIX["ğŸ”§ Self-improvement loop\nvalidate â†’ fix Â· up to 5Ã—"]
    LLM --> VER_L["âœ… Answer verification\nLLM grounding Â· borderline only"]

    COH --> RERANK["ğŸ¯ Neural reranking\nCohere rerank-english-v3.0"]
    BGE["BGE â†’ FlashRank\nlocal Â· no API needed"] -.->|if no Cohere key| RERANK

    subgraph LOCAL["No API â€” Local / Free"]
        direction LR
        L1["ğŸ“‚ Document loading\n.md  .h  .cpp"]
        L2["ğŸ“ Markdown chunking\nMarkdownNodeParser"]
        L3["âŸ¨âŸ© Code chunking\ntree-sitter AST"]
        L4["ğŸ” BM25 keyword indexing"]
        L5["âš¡ 3-way fusion retrieval\nreciprocal rank fusion"]
        L6["ğŸ” Query synonym expansion\n60+ BakkasMod domain mappings"]
        L7["ğŸ“Š Confidence scoring"]
        L8["ğŸ›¡ Circuit breakers + rate limiting"]
        L9["ğŸ’° Cost tracking + budget enforcement"]
        L10["ğŸ“‹ Structured logging"]
        L11["ğŸ”¬ SDK class browser\nCppAnalyzer Â· tree-sitter"]
        L12["ğŸ”¨ C++ validation\nMSVC compilation check"]
        L13["ğŸ”Œ MCP server\nClaude Code integration"]
    end
```

## Quick Reference

| API Key | Required? | Features |
|---|---|---|
| `OPENAI_API_KEY` | **Yes** | Vector indexing, semantic cache, answer verification (embedding), KG extraction, OpenAI GPT-4o LLM (fallback #2) |
| `ANTHROPIC_API_KEY` | No | LLM fallback #1 â€” claude-sonnet (best quality) |
| `GOOGLE_API_KEY` | No | LLM fallback #3 (Gemini 2.5 Pro Â· paid) and #5 (Gemini 2.5 Flash Â· free tier) |
| `OPENROUTER_API_KEY` | No | LLM fallback #4 â€” DeepSeek V3 (free) |
| `COHERE_API_KEY` | No | Neural reranking (falls back to BGE â†’ FlashRank locally if absent) |
| Ollama local | No | LLM fallback #6 â€” llama3.2 offline, no internet required |

## Notes

- **`OPENAI_API_KEY` has two roles**: embeddings (always used) and LLM position #2 in the fallback chain.
- **Active LLM** is resolved once at startup via live `"Say OK"` test calls â€” first provider that responds wins. All LLM-dependent features use that single resolved provider.
- **Reranking** is always active (`enable_reranker=True`); the Cohere key only determines *which* reranker is used (Cohere vs local BGE/FlashRank).
- **13 features require no external API** and work fully offline (except document loading needs the index to be built first).
