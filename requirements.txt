# Core RAG Framework
llama-index-core>=0.14.6
llama-index-llms-google-genai>=0.1.0
llama-index-llms-anthropic>=0.1.0
llama-index-llms-openai>=0.1.0
llama-index-llms-openrouter>=0.4.0  # FREE tier: DeepSeek V3, Gemini, Claude via OpenRouter
llama-index-embeddings-openai>=0.1.0
llama-index-embeddings-huggingface>=0.1.0
llama-index-retrievers-bm25>=0.1.0
llama-index-graph-stores-neo4j>=0.1.0
llama-index-postprocessor-cohere-rerank>=0.1.0  # Phase 2: Neural reranking
llama-index-postprocessor-flag-embedding-reranker>=0.1.0  # Free local reranker (BAAI/BGE)
llama-index-postprocessor-flashrank-rerank>=0.1.0  # Lightweight free reranker
FlagEmbedding>=1.3.0  # BAAI BGE reranker backend
tree-sitter-language-pack>=0.6.0  # AST-based code chunking (C++, 160+ languages)

# LLM Provider SDKs
google-genai>=1.33.0
anthropic>=0.25.0
openai>=1.0.0
cohere>=5.0.0  # Phase 2: Reranking API

# Utilities
nest-asyncio>=1.5.0
watchdog>=3.0.0
pandas>=2.0.0
pygments>=2.15.0  # Syntax highlighting for code blocks
colorama>=0.4.6  # Cross-platform colored terminal output

# GUI Framework
gradio>=4.0.0  # Web-based GUI for RAG system

# Caching (cost reduction)
gptcache>=0.1.43
faiss-cpu>=1.7.4  # For vector similarity search

# Observability & Monitoring (2026 Gold Standard)
arize-phoenix>=4.0.0  # Advanced tracing and observability
openinference-instrumentation-llama-index>=2.0.0  # LlamaIndex integration

# Evaluation & Quality Assurance
ragas>=0.1.0  # Automated RAG evaluation
datasets>=2.0.0  # For evaluation datasets

# Production & Reliability
tenacity>=8.0.0  # Retry strategies with exponential backoff
python-dotenv>=1.0.0  # Environment configuration
pydantic>=2.0.0  # Configuration validation
prometheus-client>=0.19.0  # Metrics export

# Cost Tracking
tiktoken>=0.5.0  # Token counting for cost estimation

# MCP Integration
mcp>=0.1.0

# Testing
pytest>=7.0.0
pytest-asyncio>=0.21.0
