# Core RAG Framework
llama-index-core>=0.14.6
llama-index-llms-google-genai>=0.1.0
llama-index-llms-anthropic>=0.1.0
llama-index-llms-openai>=0.1.0
llama-index-embeddings-openai>=0.1.0
llama-index-embeddings-huggingface>=0.1.0
llama-index-retrievers-bm25>=0.1.0
llama-index-graph-stores-neo4j>=0.1.0

# LLM Provider SDKs
google-genai>=1.33.0
anthropic>=0.25.0
openai>=1.0.0

# Utilities
nest-asyncio>=1.5.0
watchdog>=3.0.0
pandas>=2.0.0
pygments>=2.15.0  # Syntax highlighting for code blocks
colorama>=0.4.6  # Cross-platform colored terminal output

# Caching (cost reduction)
gptcache>=0.1.43
faiss-cpu>=1.7.4  # For vector similarity search

# Observability & Monitoring (2026 Gold Standard)
arize-phoenix>=4.0.0  # Advanced tracing and observability
openinference-instrumentation-llama-index>=2.0.0  # LlamaIndex integration

# Evaluation & Quality Assurance
ragas>=0.1.0  # Automated RAG evaluation
datasets>=2.0.0  # For evaluation datasets

# Production & Reliability
tenacity>=8.0.0  # Retry strategies with exponential backoff
python-dotenv>=1.0.0  # Environment configuration
pydantic>=2.0.0  # Configuration validation
prometheus-client>=0.19.0  # Metrics export

# Cost Tracking
tiktoken>=0.5.0  # Token counting for cost estimation

# MCP Integration
mcp>=0.1.0

# Testing
pytest>=7.0.0
pytest-asyncio>=0.21.0
